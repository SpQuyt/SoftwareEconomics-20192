{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea7cfde25cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4914e30c84ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_measures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_train = '/content/driver/My Drive/HUST/see20192/data/k59/datacsv/train_k59/*.csv'\n",
    "# path_test = '/content/driver/My Drive/HUST/see20192/data/k59/datacsv/test_k59/dataH.csv'\n",
    "\n",
    "# path_train = '/content/driver/My Drive/HUST/see20192/data/k60/datacsv/train/*.csv'\n",
    "# path_test = '/content/driver/My Drive/HUST/see20192/data/k60/datacsv/test/data_6.csv'\n",
    "\n",
    "path_train = '/content/driver/My Drive/HUST/see20192/data/k61/train/*.csv'\n",
    "path_test = '/content/driver/My Drive/HUST/see20192/data/k61/test/project_9.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(path_train)\n",
    "x_input = []\n",
    "y_output = []\n",
    "print(files)\n",
    "for file in files:\n",
    "  data = pd.read_csv(file)\n",
    "  data_xt = data['XT'].values\n",
    "  data_ac = data['AC'].values/1000\n",
    "  data_total_ac = data['TOTAL_AC'].values/1000\n",
    "\n",
    "  # data = []\n",
    "  # data.append(data_xt)\n",
    "  # data.append(data_ac)\n",
    "  # data.append(data_total_ac)\n",
    "\n",
    "  # data = np.asarray(data)\n",
    "\n",
    "  # scaler = StandardScaler()\n",
    "\n",
    "  \n",
    "  # data = scaler.fit_transform(data)\n",
    "\n",
    "  # data_xt = data[0]\n",
    "  # data_ac = data[1]\n",
    "  # data_total_ac = data[2]\n",
    "\n",
    "  print(data_total_ac)\n",
    "  # scaler = MinMaxScaler()\n",
    "  \n",
    "#dung de lay du lieu theo cap\n",
    "  data_input2D = []\n",
    "  data_output1D = []\n",
    "  steps = 3\n",
    "  \n",
    "  for i in range(0,len(data_xt)-steps+1):\n",
    "    temp_3D = []\n",
    "    for k in range(i, i+steps):\n",
    "      temp_2D = []\n",
    "      temp_2D.append(data_xt[k])\n",
    "      temp_2D.append(data_ac[k])\n",
    "      \n",
    "      temp_3D.append(temp_2D)\n",
    "\n",
    "    data_output1D.append(data_total_ac[i])\n",
    "\n",
    "    data_input2D.append(temp_3D)\n",
    "  x_input.append(data_input2D)\n",
    "  y_output.append(data_output1D)\n",
    "\n",
    "x_input = np.concatenate( x_input, axis=0 )\n",
    "y_output = np.concatenate( y_output, axis=0 )\n",
    "x_train = np.asarray(x_input)\n",
    "y_train = np.asarray(y_output)\n",
    "\n",
    "x_train = x_train.reshape(-1,3,2)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 3\n",
    "n_features = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, activation='relu', input_shape=(n_input, n_features)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1500, validation_split=0.1, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path_test)\n",
    "ip_test_xt = test['XT'].values.astype('float64') \n",
    "ip_test_ac = test['AC'].values.astype('float64')/1000\n",
    "test_output = test['TOTAL_AC'].values.astype('float64')\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# print(test_output)\n",
    "# ip_test_xt = scaler.fit_transform(ip_test_xt.reshape(-1,1))\n",
    "# ip_test_ac = scaler.fit_transform(ip_test_ac.reshape(-1,1))\n",
    "# test_output = scaler.fit_transform(test_output.reshape(-1,1))\n",
    "x_input=[]\n",
    "y_output =[]\n",
    "\n",
    "data_input2D = []\n",
    "data_output1D = []\n",
    "steps = 3\n",
    "\n",
    "for i in range(0,len(ip_test_xt)-steps+1):\n",
    "  temp_3D = []\n",
    "  for k in range(i, i+steps):\n",
    "    temp_2D = []\n",
    "    temp_2D.append(ip_test_xt[k])\n",
    "    temp_2D.append(ip_test_ac[k])\n",
    "    \n",
    "    temp_3D.append(temp_2D)\n",
    "\n",
    "  data_input2D.append(temp_3D)\n",
    "x_input.append(data_input2D)\n",
    "\n",
    "\n",
    "x_input = np.concatenate( x_input, axis=0 )\n",
    "\n",
    "\n",
    "x_test = x_input.reshape(-1,3,2)\n",
    "\n",
    "result = model.predict(x_test)\n",
    "\n",
    "result = result*1000\n",
    "# result = scaler.inverse_transform(result)\n",
    "\n",
    "\n",
    "plt.plot(result,'x', color='r')\n",
    "plt.plot(test_output, 'o' ,color='b')\n",
    "plt.title(\"Mô hình K60\")\n",
    "plt.xlabel(\"STT\")\n",
    "plt.ylabel(\"Cost\")\n",
    "# mplcursors.cursor(hover=True)\n",
    "print(\"actually: \",test_output)\n",
    "print(\"model: \", result)\n",
    "percent = []\n",
    "acc = 0\n",
    "for i in range(0,result.size):\n",
    "  p = (1- abs(test_output[i]-result[i])/test_output[i])*100\n",
    "  percent.append(p)\n",
    "  acc += p\n",
    "print(\"pecent: \", percent)\n",
    "print(\"accuracy: \", acc/(result.size))\n",
    "\n",
    "plt.legend(('prediction', 'reality'),loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
